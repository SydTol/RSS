{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Particle Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to tutorial 3 of the tutorials. Last week we looked at grid localization, this week we will be looking at particles filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import copy as copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Outline of the Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objectives:**\n",
    "* Define the robot's environment i.e. robot moves, action and measurement noise\n",
    "* Learn how to use particle filters \n",
    "* Understand the concept of importance sampling and how it is used in particle filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In last week's tutorial we looked at grid localization, which is suitable for small-scale problems i.e. a grid of small size. Grid localization has limitations when applied to larger scale problems:\n",
    "* The continuous space is discretized into finite grids\n",
    "* Higher grid resolution requires more memory storage\n",
    "* Once discretized, the resolution of the grid is fixed, no way of adapting memory allocation \n",
    "\n",
    "Particle filters however, can overcome these problems. The key idea behind using particle filters is to represent the belief $bel(x_t)$ using a set of samples or particles drawn from posterior belief rather than using the entire distribution. In other words, particle filters approximate the belief $bel(x_t)$ by a set of particles:\n",
    "\n",
    "$\\chi_t := x^{[1]}_t, x^{[2]}_t,...,x^{[M]}_t$\n",
    "\n",
    "Each particle $x^{[m]}_t$ is a hypothesis as to what the true world state may be at time $t$. $M$ denotes the number of particles in a set $\\chi_t$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/sense_move_act.png\" style=\"width: 600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to last weeks tutorial on grid localization, the robot follows the same loop of moving and sensing. However instead of using a grid localization method, we will be using a particle filter for state estimation. The figure below shows the robot (red circle) in its state space. The orange circles show landmarks within the state space. The robot uses these landmarks in order to localize itself within the state space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/particle_filter.png\" style=\"width: 600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Utility Functions\n",
    "Define Gaussian function which will be used later for the measurement model \"likelihood\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(mu, sigma, x):        \n",
    "    # Given a x position, mean mu and std sigma of Gaussian, calculates the probability\n",
    "    # Note\n",
    "    # mu: estimated distance by each particle's position, (map and landmarks are known)\n",
    "    # x:  measured distance by the robot\n",
    "    return np.exp(- ((mu - x) ** 2) / (sigma ** 2) / 2.0) / np.sqrt(2.0 * np.pi * (sigma ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Define Robot World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the robot's world, defining the motion model, sensing function and the likelihood evaluation function: \n",
    "* Create simulated sensing: $Z_t = d(x_t) + \\mathcal{N}(0, \\sigma^2) $, where $d(x_t)$ is the actual distance to the landmark and $\\mathcal{N}(0, \\sigma^2)$ is Gaussian noise from the sensor\n",
    "\n",
    "* Motion model equation: $ p(x^{[m]}_{t}$ | $u_t, x^{[m]}_{t-1}$)\n",
    "* Measurement model \"importance factor\": $ p(z_t$ | $ x^{[m]}_{t}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 100.0\n",
    "landmarks  = [[50.0, 50.0], [world_size, world_size], [0.0, world_size], [world_size, 0.0]]\n",
    "\n",
    "class Robot(object):\n",
    "    def __init__(self):\n",
    "        #  random.random() returns random number in [0.0, 1.0)\n",
    "        self.x = np.random.rand() * world_size\n",
    "        self.y = np.random.rand() * world_size\n",
    "        self.orientation = np.random.rand() * 2.0 * np.pi\n",
    "        self.forward_noise = 0.0;\n",
    "        self.turn_noise    = 0.0;\n",
    "        self.sense_noise   = 0.0;\n",
    "    \n",
    "    def set_pose(self, new_x, new_y, new_orientation):\n",
    "        # Define limits for robot\n",
    "        # Can set the pose of the robot after initialization\n",
    "        if new_x < 0 or new_x >= world_size:\n",
    "            raise ValueError('X coordinate out of bound')\n",
    "        if new_y < 0 or new_y >= world_size:\n",
    "            raise ValueError('Y coordinate out of bound')\n",
    "        if new_orientation < 0 or new_orientation >= 2 * np.pi:\n",
    "            raise ValueError('Orientation must be in [0..2pi]')\n",
    "        self.x = float(new_x)\n",
    "        self.y = float(new_y)\n",
    "        self.orientation = float(new_orientation)\n",
    "    \n",
    "    def set_noise(self, new_f_noise, new_t_noise, new_s_noise):\n",
    "        # possibility to set noise parameters for forward, turn and sensing\n",
    "        # this is often useful in particle filters\n",
    "        self.forward_noise = float(new_f_noise);\n",
    "        self.turn_noise    = float(new_t_noise);\n",
    "        self.sense_noise   = float(new_s_noise);\n",
    "    \n",
    "    def sense(self):\n",
    "        # Measure the distance to landmarks with some noise\n",
    "        Z = []\n",
    "        for i in range(len(landmarks)):\n",
    "            # given its position x, y, measure the distance to each landmark\n",
    "            dist = np.sqrt((self.x - landmarks[i][0]) ** 2 + (self.y - landmarks[i][1]) ** 2)\n",
    "            # superimpose a gaussian noise on ideal measurement\n",
    "            dist += np.random.randn()*self.sense_noise\n",
    "            Z.append(dist)\n",
    "        return Z\n",
    "    \n",
    "    def move(self, turn, forward):\n",
    "        if forward < 0:\n",
    "            raise ValueError('Robot cant move backwards')         \n",
    "        \n",
    "        # turn, and add Gaussian noise to the turning command\n",
    "        orientation = self.orientation + float(turn) + np.random.randn()*self.turn_noise\n",
    "        orientation %= 2 * np.pi # make sure: 0=< orientation <=2*pi \n",
    "        \n",
    "        # move, and add Gaussian noise to the motion command\n",
    "        dist = float(forward) + np.random.randn()*self.forward_noise\n",
    "        x = self.x + (np.cos(orientation) * dist)\n",
    "        y = self.y + (np.sin(orientation) * dist)\n",
    "        x %= world_size    # make sure: 0=< position <= world_size\n",
    "        y %= world_size\n",
    "        \n",
    "        # set the new location x, y back to the member variables x y of the class\n",
    "        self.set_pose(x, y, orientation)\n",
    "        return None\n",
    "    \n",
    "    def measurement_prob(self, measurement):        \n",
    "        # calculates how likely a measurement should be based on a Gaussian distribution        \n",
    "        prob = 1.0;\n",
    "        for i in range(len(landmarks)):\n",
    "            # calculate probability of being in a location given a measurement \n",
    "            dist = np.sqrt((self.x - landmarks[i][0]) ** 2 + (self.y - landmarks[i][1]) ** 2)\n",
    "            prob *= gaussian(dist, self.sense_noise, measurement[i])\n",
    "            # the final probability is the multiplication of each measurement probability\n",
    "        return prob\n",
    "    \n",
    "    def __repr__(self):\n",
    "        # return a printable pose of the robot\n",
    "        return 'Robot pose is: [x=%.5s y=%.5s orient=%.5s]' % (str(self.x), str(self.y), str(self.orientation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Functions for Robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(x):\n",
    "    print(np.around(x,decimals=3))\n",
    "        \n",
    "        \n",
    "def plotRobot(robot):\n",
    "    # Used for visualizing the robot and landmarks on scatter plot \n",
    "\n",
    "    plt.figure(num=None, figsize=(20, 15), dpi=80, facecolor='w', edgecolor='k')\n",
    "    \n",
    "    # Plotting the landmarks \n",
    "    for l in landmarks:\n",
    "        plt.scatter(l[0], l[1], c='c', s =1000)\n",
    "        \n",
    "    # Plotting robot position     \n",
    "    plt.scatter(robot.x, robot.y, c='r', s=500)\n",
    "    \n",
    "    # Plotting robot orientation     \n",
    "    plt.quiver(robot.x, robot.y, 5,5, angles=np.rad2deg(robot.orientation), scale=1/5, scale_units=\"dots\",\n",
    "          units=\"dots\", color=\"k\", pivot=\"mid\",width=2.5, headwidth=5, headlength=2.5)\n",
    "    \n",
    "    plt.xlim(0, world_size)\n",
    "    plt.ylim(0, world_size)\n",
    "    plt.show(block=False)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Previously Defined Functions and Class\n",
    "\n",
    "**Tasks:** \n",
    "1. Use the motion model and the measurement model\n",
    "2. Modify the motion command and the uncertainties of motion to see how the robot moves\n",
    "3. Use measurement model to obtain landmark measurement and modify uncertainties of the sensing to see it senses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# init robot\n",
    "robot = Robot()\n",
    "# set noise levels\n",
    "robot.set_noise(0.01, .01, 0.01)\n",
    "\n",
    "# set an initial position for the robot at the centre of the environment\n",
    "robot.set_pose(50.0, 50.0, 0*np.pi/2) \n",
    "print('\\nDistance from 4 landmarks')\n",
    "show(robot.sense())\n",
    "print('Robot location \\n', robot)\n",
    "# plot robot in environment\n",
    "plotRobot(robot)\n",
    "\n",
    "# Move the robot 10 steps at an orientation of 45 degrees (plotting robot position) \n",
    "# and obtain a measurement of the landmarks\n",
    "### START CODE HERE ### (~ 3-5 lines of code)\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Move the robot 15 steps up from this position\n",
    "# and obtain a measurement of the landmarks\n",
    "### START CODE HERE ### (~ 3-5 lines of code)\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Robot objects are mutable! \n",
    "# a mutable object can be changed after it is created\n",
    "robot_array = []\n",
    "robot_array.append(robot)\n",
    "robot_array.append(robot)\n",
    "robot_array.append(copy(robot))\n",
    "robot.move(0,10)\n",
    "\n",
    "#print('\\nShowing off the mutability of Robot')\n",
    "#print('Array problem \\n', robot_array[1])\n",
    "#print('Array solution \\n', robot_array[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Plotting Function For Particles and Robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotParticles(robot, particles):\n",
    "    # Used for visualizing the particles, robot and landmarks on scatter plot \n",
    "    \n",
    "    plt.figure(num=None, figsize=(20, 15), dpi=80, facecolor='w', edgecolor='k')\n",
    "    \n",
    "    # Plotting the particles\n",
    "    for p in particles:\n",
    "        plt.scatter(p.x, p.y, c='b')\n",
    "        plt.quiver(p.x, p.y, 1,1, angles=np.rad2deg(p.orientation), scale=1/5, scale_units=\"dots\", \n",
    "                   units=\"dots\", color=\"y\", pivot=\"mid\",width=1.25, headwidth=2, headlength=0.5)\n",
    "\n",
    "    # Plotting the landmarks \n",
    "    for l in landmarks:\n",
    "        plt.scatter(l[0], l[1], c='c', s =1000)\n",
    "        \n",
    "    # Plotting robot position     \n",
    "    plt.scatter(robot.x, robot.y, c='r', s=500)\n",
    "    \n",
    "    # Plotting robot orientation     \n",
    "    plt.quiver(robot.x, robot.y, 5,5, angles=np.rad2deg(robot.orientation), scale=1/5, scale_units=\"dots\",\n",
    "          units=\"dots\", color=\"k\", pivot=\"mid\",width=2.5, headwidth=5, headlength=2.5)\n",
    "    \n",
    "    plt.xlim(0, world_size)\n",
    "    plt.ylim(0, world_size)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Particle Filter Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/particle_filter_pseudo.png\" style=\"width: 600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Line-by-line Description:**\n",
    "\n",
    "**Line 1.** The particle filter has the previous particle set $\\chi_{t-1}$, latest action $u_t$ and latest sensor reading $z_t$ as inputs\n",
    "\n",
    "**Line 2.** The temporary particle set $\\bar{\\chi}_t$ is initialized\n",
    "\n",
    "**Line 3.** Looping over each particle with index $m$ over number of particles $M$\n",
    "\n",
    "**Line 4.** Generate a hypothetical state $x^{[m]}_t$ using the motion model: $ p(x^{[m]}_{t}$ | $u_t, x^{[m]}_{t-1}$)\n",
    "\n",
    "**Line 5.** Calculate the importance factor or weight $w^{[m]}_t$ using the measurement model: $p(z_t | x^{[m]}_t)$\n",
    "\n",
    "**Line 6.** Add the weights and particles to temporary particle set $\\bar{\\chi}_t$\n",
    "\n",
    "**Lines 8-11.** Implement resampling or importance sampling:\n",
    "* Loop through the set of particles, drawing particles from the temporary particle set $\\bar{\\chi}_t$. \n",
    "* The probability of drawing each particle is given by its importance weight $w^{[m]}_t$.\n",
    "* Resampling updates the particle set, incorporating the weights to change the distribution of particles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particle Filter Algorithm Implementation\n",
    "**Task:**\n",
    "Change the particle update function to use the stochastic universal sampling method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleFilterStateEstimator(object):\n",
    "    def __init__(self, noParticles):\n",
    "        self.particles = []\n",
    "        self.weights = []\n",
    "        # create a list of particles with random initial state\n",
    "        for _ in range(noParticles):\n",
    "            p = Robot()\n",
    "            p.set_noise(0.1, 0.1, 5.0)\n",
    "            self.particles.append(p)\n",
    "    \n",
    "    # update the pose of each particle according to the motion model defined above function \"move()\"  \n",
    "    # where action is a list of [delta in heading, delta in forward motion]    \n",
    "    def actionUpdate(self, action):\n",
    "        for p in self.particles:\n",
    "            p.move(action[0],action[1])\n",
    "\n",
    "    # Measurement model - importance factor:\n",
    "    def measurementUpdate(self, measurement):      \n",
    "        weights = []\n",
    "        for p in self.particles:\n",
    "            # Obtain weight w \n",
    "            weights.append(p.measurement_prob(measurement))\n",
    "        \n",
    "        # Normalize w (total probability)\n",
    "        ### START CODE HERE ### (~1-2 lines of code)\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    # Particle update: given each particle's position, what is the probability \n",
    "    # of being at that position given Z measurement          \n",
    "    def particleUpdate(self):      \n",
    "        self.particles = resampling(self.particles, self.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Resampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resampling or importance sampling step can be thought of as a probabilistic implementation of the Darwinian idea of *survival of the fittest*. It refocuses the particle set to regions in the state space with higher probability. By doing so, it focuses computational resources of the filter algorithm more efficiently. \n",
    "\n",
    "Before the resampling step, the particles were distributed according to the motion model, giving $\\bar{bel}(x_t)$. After resampling, (lines 8-11) the particles are redistributed according to the posterior: $bel(x_t)$ =  $p(z_t | x^{[m]}_t)$ $ p(x^{[m]}_{t}$ | $u_t, x^{[m]}_{t-1}$). This results in a new particle distribution after one motion model update and one measurement model update.\n",
    "\n",
    "The figure below shows this process:\n",
    "\n",
    "(a) The target density f which corresponds to $bel(x_t)$ \n",
    "\n",
    "(b) The actual density g, who's distribution is sampled according to the motion model i.e. $\\bar{bel}(x_t)$. Particle samples for g are also shown, taken according to line 4 in the algorithm.\n",
    "\n",
    "(c) Particles are redistrubuted or resampled from f by attaching the weights to each particle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/importance_sampling.png\" style=\"width: 600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling Algorithm Implementation\n",
    "\n",
    "One significant source of error in particle filters is that whenever samples are drawn from a probability density, the extracted statistics (e.g. mean and variance) of these samples will be slightly different to the statistics of the original probability density. This is called *Sampling Variance* and is worsened when repeated resampling occurs, such as in a particle filter.\n",
    "\n",
    "This problem can be addressed by not selecting samples independently of each other during the resampling process, but instead by using a sequential stochastic process. Two sequential resampling algorithms are provided below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampling(particles, w):\n",
    "    N = len(particles)\n",
    "    beta=0\n",
    "    index=0\n",
    "    w_max= max(w)\n",
    "    p_temp=[]\n",
    "    for i in range(N):\n",
    "        beta= beta+2.0*w_max*np.random.rand()\n",
    "        while beta>w[index]:\n",
    "            beta = beta - w[index]\n",
    "            index=(index + 1) % N\n",
    "        selectedParticle = copy(particles[index])\n",
    "        p_temp.append(selectedParticle) # if beta<w[index], this indexed particle is selected\n",
    "    return p_temp\n",
    "\n",
    "def stochasticUniversalSampling(particles, weights):\n",
    "    N = len(particles)\n",
    "    beta = np.random.rand()/N\n",
    "    index = 0    \n",
    "    p_temp = []\n",
    "    for i in range(N):\n",
    "        beta += 1.0/N\n",
    "        while beta>weights[index]:\n",
    "            beta = beta - weights[index]\n",
    "            index= (index + 1) % N\n",
    "        selectedParticle = copy(particles[index])\n",
    "        p_temp.append(selectedParticle) # if beta<w[index], this indexed particle is selected \n",
    "    return p_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple evaluation function, regarding the accuracy (compare against ground truth) of the estimation (localization) process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(robot, particles):\n",
    "    # Gives the mean error in position between the robot's\n",
    "    # actual position and the set of particles\n",
    "    sum = 0.0;\n",
    "    for p in particles: # calculate mean error \n",
    "        dx = (p.x - robot.x + (world_size/2.0)) % world_size - (world_size/2.0)\n",
    "        dy = (p.y - robot.y + (world_size/2.0)) % world_size - (world_size/2.0)\n",
    "        err = np.sqrt(dx * dx + dy * dy)\n",
    "        sum += err\n",
    "    return sum / float(len(particles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Test Particle Filter Localization \n",
    "Test the particle filter localization using the developed functions and class.\n",
    "\n",
    "**Tasks:** \n",
    "1. Fill in the missing parts of the particle filter algorithm, using functions from the *ParticleFilterStateEstimator* class\n",
    "2. Use and compare the two differrent resampling algorithms. (Tip: modify function *particleUpdate()* in *ParticleFilterStateEstimator* class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Create an object called \"myrobot\", which we will use as the real robot, enter code below.\n",
    "    # Note: that robot does not have noise, we need this info as ground truth\n",
    "    myrobot = Robot()\n",
    "    myrobot.set_pose(0.0, 0.0, 0)   \n",
    "    myrobot.set_noise(0.0, 0.0, 0.0)\n",
    "    \n",
    "    # Set the motion the robot will perform\n",
    "    steps=10\n",
    "    heading = 10.0/180.0*np.pi\n",
    "    steplength = 10.0\n",
    "    \n",
    "    # Initialize the state estimator\n",
    "    estimator = ParticleFilterStateEstimator(1500)\n",
    "    # plot robot, environment and particles    \n",
    "    plotParticles(myrobot, estimator.particles)\n",
    "    \n",
    "    # for each step update the belief     \n",
    "    for s in range(steps):\n",
    "        \n",
    "        # Implement the particle filter algorithm\n",
    "        # move robot         \n",
    "        myrobot.move(heading, steplength)\n",
    "        \n",
    "        # update pose of each particle according to the motion model         \n",
    "        ### START CODE HERE ### (~1 line of code)\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # obtain a sensor reading         \n",
    "        measurement = myrobot.sense()\n",
    "        \n",
    "        # update the weights of the particles according to the measrement model \n",
    "        ### START CODE HERE ### (~1 line of code)\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # update the particles according to resampling process \n",
    "        ### START CODE HERE ### (~1 line of code)\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        print('Step: ',  s) \n",
    "        print('Robot location:', myrobot) \n",
    "        print(\"Mean error:\",evaluation(myrobot, estimator.particles))\n",
    "        plotParticles(myrobot, estimator.particles)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
